{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "528894c1-ccbe-4930-aaf2-f8abbeb81bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from astropy.io import fits \n",
    "from astropy.stats import sigma_clip\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "def create_median_bias(bias_list, median_bias_filename):\n",
    "    \"\"\"Creates a median bias frame from a list of FITS bias files.\n",
    "\n",
    "    Parameters:\n",
    "    - bias_list: list of strings, paths to bias FITS files.\n",
    "    - median_bias_filename: string, path to save the resulting median bias frame.\n",
    "\n",
    "    Returns:\n",
    "    - A 2D numpy array of the median bias frame.\n",
    "    \"\"\"\n",
    "    # read all bias frames into a 3D numpy array (stack of 2D images)\n",
    "    bias_frames = []\n",
    "    for file in bias_list:\n",
    "        data = fits.getdata(file).astype('f4')\n",
    "        bias_frames.append(data)\n",
    "        \n",
    "    bias_stack = np.array(bias_frames)\n",
    "    \n",
    "    # apply sigma clipping along the stack axis (axis=0)\n",
    "    clipping = sigma_clip(bias_stack, cenfunc = 'median', sigma=3.0, axis=0)\n",
    "    \n",
    "\n",
    "    # take the median of the clipped data\n",
    "    # convert masked array to regular ndarray before saving\n",
    "    median_bias = np.ma.median(clipping, axis=0)\n",
    "    if isinstance(median_bias, np.ma.MaskedArray):\n",
    "        median_bias = median_bias.filled()\n",
    "    # returns fits immages \n",
    "    primary = fits.PrimaryHDU(data=median_bias, header=fits.Header())\n",
    "    hdul = fits.HDUList([primary])\n",
    "    hdul.writeto(median_bias_filename, overwrite=True)\n",
    "\n",
    "    return median_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f4037e-35f9-45df-a505-26529c1d4df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "#\n",
    "# @Filename: darks.py\n",
    "# @License: BSD 3-clause (http://www.opensource.org/licenses/BSD-3-Clause)\n",
    "\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.stats import sigma_clip\n",
    "import numpy as np\n",
    "\n",
    "def create_median_dark(dark_list, bias_filename, median_dark_filename):\n",
    "    \"\"\"Creates a median dark frame corrected for bias and normalized by exposure time.\n",
    "\n",
    "    Parameters:\n",
    "    - dark_list: list of strings, paths to dark FITS files.\n",
    "    - bias_filename: string, path to the median bias FITS file.\n",
    "    - median_dark_filename: string, path to save the resulting median dark frame.\n",
    "\n",
    "    Returns:\n",
    "    - A 2D numpy array of the median dark frame.\n",
    "    \"\"\"\n",
    "\n",
    "    # load the median bias frame\n",
    "    bias_data = fits.getdata(bias_filename).astype('f4')\n",
    "\n",
    "    # list to store bias-subtracted and normalized dark frames\n",
    "    dark_corrected_frames = []\n",
    "\n",
    "    for path in dark_list:\n",
    "        with fits.open(path) as dark:\n",
    "            dark_data = dark[0].data.astype('f4')\n",
    "            exptime = dark[0].header['EXPTIME']\n",
    "            if exptime <= 0:\n",
    "                raise ValueError(f\"Invalid EXPTIME ({exptime}) in {path}\")\n",
    "            dark_nobias = dark_data - bias_data\n",
    "            dark_corrected_frames.append(dark_nobias / exptime)\n",
    "            header = dark[0].header.copy()\n",
    "\n",
    "\n",
    "    # stack and sigma clip the corrected dark frames\n",
    "    dark_3d = np.array(dark_corrected_frames)\n",
    "    clipping = sigma_clip(dark_3d, cenfunc = 'median', sigma=3.0, axis=0)\n",
    "\n",
    "    # compute the median of the clipped data\n",
    "    median_dark = np.ma.median(clipping, axis=0).filled()\n",
    "\n",
    "    # save to a FITS file\n",
    "    dark_hdu = fits.PrimaryHDU(data=median_dark, header=fits.Header())\n",
    "    dark_hdu.writeto(median_dark_filename, overwrite=True)\n",
    "\n",
    "    return median_dark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93458c54-2a09-43b8-bc39-5cdc6c49cfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def create_median_flats_per_filter(flat_files, bias_file, dark_file=None, output_dir=\".\"):\n",
    "    \"\"\"\n",
    "    Create median flats grouped by filter.\n",
    "\n",
    "    flat_files: list of flat FITS file paths\n",
    "    bias_file: path to median bias FITS\n",
    "    dark_file: optional median dark FITS path\n",
    "    output_dir: where to save median flats\n",
    "    \n",
    "    Saves median flats named median_flat_<filter>.fits\n",
    "    \"\"\"\n",
    "    # load bias and dark data once\n",
    "    bias_data = fits.getdata(bias_file)\n",
    "    dark_data = fits.getdata(dark_file) if dark_file else None\n",
    "    \n",
    "    # group flats by FILTER header\n",
    "    flats_by_filter = defaultdict(list)\n",
    "    for f in flat_files:\n",
    "        with fits.open(f) as hdul:\n",
    "            filter_name = hdul[0].header.get(\"FILTER\", \"UNKNOWN\")\n",
    "        flats_by_filter[filter_name].append(f)\n",
    "    \n",
    "    for filter_name, files in flats_by_filter.items():\n",
    "        print(f\"Processing {len(files)} flats for filter {filter_name}\")\n",
    "        calibrated_flats = []\n",
    "        for fname in files:\n",
    "            flat_data = fits.getdata(fname)\n",
    "            # Bias subtract\n",
    "            flat_corr = flat_data - bias_data\n",
    "            # Dark subtract if available\n",
    "            if dark_data is not None:\n",
    "                flat_corr -= dark_data\n",
    "            calibrated_flats.append(flat_corr)\n",
    "        \n",
    "        # stack and median combine\n",
    "        stack = np.array(calibrated_flats)\n",
    "        median_flat = np.median(stack, axis=0)\n",
    "        \n",
    "        # normalize\n",
    "        median_val = np.median(median_flat)\n",
    "        if median_val == 0:\n",
    "            raise ValueError(f\"Median of flat for filter {filter_name} is zero\")\n",
    "        median_flat /= median_val\n",
    "        \n",
    "        # save\n",
    "        outname = os.path.join(output_dir, f\"median_flat_{filter_name}.fits\")\n",
    "        fits.PrimaryHDU(data=median_flat).writeto(outname, overwrite=True)\n",
    "        print(f\"Saved median flat for filter {filter_name} to {outname}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1147d0e7-d876-41a9-ba96-fa0e9dbba802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "from photutils.detection import find_peaks\n",
    "from photutils.segmentation import detect_sources\n",
    "from scipy.ndimage import median_filter\n",
    "\n",
    "def reduce_science_frame(\n",
    "    science_filename,\n",
    "    median_bias_filename,\n",
    "    median_flat_filename,\n",
    "    median_dark_filename,\n",
    "    reduced_science_filename=\"reduced_science.fits\",\n",
    "):\n",
    "    \"\"\"Reduce a science frame using bias, dark, and flat frames.\"\"\"\n",
    "\n",
    "    # load all data\n",
    "    with fits.open(science_filename) as hdul:\n",
    "        science_header = hdul[0].header\n",
    "        exposure_time = science_header.get('EXPTIME')\n",
    "        science_data = fits.getdata(science_filename).astype('f4')\n",
    "\n",
    "    bias_data = fits.getdata(median_bias_filename).astype('f4')\n",
    "    dark_data = fits.getdata(median_dark_filename).astype('f4')\n",
    "    flat_data = fits.getdata(median_flat_filename).astype('f4')\n",
    "    \n",
    "\n",
    "    # subtract bias\n",
    "    reduced_science = science_data - bias_data\n",
    "\n",
    "    # subtract dark (scaled by exposure time)\n",
    "    reduced_science -= dark_data * exposure_time\n",
    "\n",
    "    # flat field correction\n",
    "    reduced_science /= flat_data\n",
    "\n",
    "    # remove cosmic rays (simple median filter + threshold method)\n",
    "    # this can be replaced with astroscrappy or similar for better accuracy\n",
    "    smoothed = median_filter(reduced_science, size=3)\n",
    "    residual = reduced_science - smoothed\n",
    "    threshold = 5 * np.std(residual)\n",
    "    mask = residual > threshold\n",
    "    reduced_science[mask] = smoothed[mask]  # Replace cosmic rays\n",
    "\n",
    "    # save to FITS\n",
    "    primary_science = fits.PrimaryHDU(data=reduced_science.data, header=fits.Header())\n",
    "    primary_science.writeto(reduced_science_filename, overwrite=True)\n",
    "\n",
    "    return reduced_science\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cd0e23-3bc9-4dd0-81ab-8b64462ada97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# define the data directory\n",
    "data_dir = Path(\"astr-480-env/work/arcsat_data/scripts/data\")  # Adjust path depending on location of .fit files\n",
    "\n",
    "# load and ort your calibration frames\n",
    "bias_files = sorted([str(f) for f in data_dir.glob(\"Bias_*.fits\")])\n",
    "dark_files = sorted([str(f) for f in data_dir.glob(\"Dark_*.fits\")])\n",
    "flat_files = sorted([str(f) for f in data_dir.glob(\"domeflat_*.fits\")])\n",
    "sci_files = sorted([str(f) for f in data_dir.glob(\"Cats_*.fits\")])\n",
    "print(\"Bias files:\", bias_files)\n",
    "\n",
    "#implementing functions\n",
    "create_median_bias(bias_files, str(data_dir / \"median_bias.fits\"))\n",
    "create_median_dark(dark_files, str(data_dir / \"median_bias.fits\"), str(data_dir / \"median_dark.fits\"))\n",
    "create_median_flats_per_filter(\n",
    "    flat_files=flat_files,\n",
    "    bias_file=str(median_bias_file),\n",
    "    dark_file=str(median_dark_file),\n",
    "    output_dir=str(data_dir)\n",
    ")\n",
    "\n",
    "#making sure the median flats and images are sorted in the same way \n",
    "median_flats = sorted(data_dir.glob(\"median_flat_*.fits\"))\n",
    "images = sorted(data_dir.glob(\"Cats_*.fits\"))\n",
    "\n",
    "# reduce science frame manually for each science frame \n",
    "reduce_science_frame(\n",
    "    science_filename=sci_files[0],\n",
    "    median_bias_filename=str(data_dir / \"median_bias.fits\"),\n",
    "    median_dark_filename=str(data_dir / \"median_dark.fits\"),\n",
    "    median_flat_filename=str(median_flats[0]),\n",
    "    reduced_science_filename = str(data_dir / (\"reduced_\" + Path(sci_files[0]).name))\n",
    ")\n",
    "\n",
    "reduce_science_frame(\n",
    "    science_filename=sci_files[1],\n",
    "    median_bias_filename=str(data_dir / \"median_bias.fits\"),\n",
    "    median_dark_filename=str(data_dir / \"median_dark.fits\"),\n",
    "    median_flat_filename=str(median_flats[1]),\n",
    "    reduced_science_filename = str(data_dir / (\"reduced_\" + Path(sci_files[1]).name))\n",
    ")\n",
    "\n",
    "reduce_science_frame(\n",
    "    science_filename=sci_files[2],\n",
    "    median_bias_filename=str(data_dir / \"median_bias.fits\"),\n",
    "    median_dark_filename=str(data_dir / \"median_dark.fits\"),\n",
    "    median_flat_filename=str(median_flats[2]),\n",
    "    reduced_science_filename = str(data_dir / (\"reduced_\" + Path(sci_files[2]).name))\n",
    ")\n",
    "\n",
    "reduce_science_frame(\n",
    "    science_filename=sci_files[3],\n",
    "    median_bias_filename=str(data_dir / \"median_bias.fits\"),\n",
    "    median_dark_filename=str(data_dir / \"median_dark.fits\"),\n",
    "    median_flat_filename=str(median_flats[3]),\n",
    "    reduced_science_filename = str(data_dir / (\"reduced_\" + Path(sci_files[3]).name))\n",
    ")\n",
    "\n",
    "reduce_science_frame(\n",
    "    science_filename=sci_files[4],\n",
    "    median_bias_filename=str(data_dir / \"median_bias.fits\"),\n",
    "    median_dark_filename=str(data_dir / \"median_dark.fits\"),\n",
    "    median_flat_filename=str(median_flats[4]),\n",
    "    reduced_science_filename = str(data_dir / (\"reduced_\" + Path(sci_files[4]).name))\n",
    ")\n",
    "\n",
    "\n",
    "# show results (wanted to make sure it was running properly so I ran for H-Alpha and r filters\n",
    "with fits.open(data_dir / f\"reduced_{Path(sci_files[0]).name}\") as hdul:\n",
    "    plt.imshow(hdul[0].data, cmap='gray', origin='lower', vmin=0, vmax=np.percentile(hdul[0].data, 99))\n",
    "    plt.title(\"Reduced Science Frame\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "with fits.open(data_dir / f\"reduced_{Path(sci_files[3]).name}\") as hdul:\n",
    "    plt.imshow(hdul[0].data, cmap='gray', origin='lower', vmin=0, vmax=np.percentile(hdul[0].data, 99))\n",
    "    plt.title(\"Reduced Science Frame\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e63a611-f6ff-4d01-bc83-6b4fc361c3a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c400e9da-1e35-4364-984f-485aefb1e51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#generating an RGB composite for nebula \n",
    "g_data = fits.getdata('astr-480-env/work/arcsat_data/scripts/data/reduced_Cats_Eye_Nebula_g_20250601_065904.fits')\n",
    "r_data = fits.getdata('astr-480-env/work/arcsat_data/scripts/data/reduced_Cats_Eye_Nebula_r_20250601_065842.fits')\n",
    "i_data = fits.getdata('astr-480-env/work/arcsat_data/scripts/data/reduced_Cats_Eye_Nebula_i_20250601_065929.fits')\n",
    "\n",
    "def normalize(image, low=0.5, high=99.5):\n",
    "    vmin, vmax = np.percentile(image, [low, high])\n",
    "    norm = np.clip((image - vmin) / (vmax - vmin), 0, 1)\n",
    "    return norm\n",
    "\n",
    "R = normalize(i_data)  # i' as red\n",
    "G = normalize(r_data)  # r' as green\n",
    "B = normalize(g_data)  # g' as blue\n",
    "\n",
    "rgb = np.dstack((R, G, B))\n",
    "\n",
    "#plotting\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(rgb, origin='lower')\n",
    "plt.axis('off')\n",
    "plt.title('RGB Composite')\n",
    "plt.savefig('RGB Composite')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016f369d-d9fa-4d4c-ad5f-2bbde931cd62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#reduced science image in r filter \n",
    "\n",
    "with fits.open(data_dir / f\"reduced_{Path(sci_files[3]).name}\") as hdul:\n",
    "    plt.imshow(hdul[0].data, cmap='gray', origin='lower', vmin=0, vmax=np.percentile(hdul[0].data, 99))\n",
    "    plt.title(\"Reduced Science Frame\")\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df83a112-7232-4471-b9f2-22937612a33e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "\n",
    "def calculate_gain(files):\n",
    "    \"\"\"\n",
    "    Calculate the detector gain (e-/ADU) using two flat-field images.\n",
    "\n",
    "    Parameters:\n",
    "        files (list): List of two flat-field FITS file paths.\n",
    "\n",
    "    Returns:\n",
    "        float: Calculated gain in e-/ADU.\n",
    "    \"\"\"\n",
    "    if len(files) != 2:\n",
    "        raise ValueError(\"You must provide exactly two flat-field images.\")\n",
    "\n",
    "    # Read the flat-field images\n",
    "    flat1 = fits.getdata(files[0]).astype('f4')\n",
    "    flat2 = fits.getdata(files[1]).astype('f4')\n",
    "\n",
    "    # Calculate mean and variance\n",
    "    mean1 = np.mean(flat1)\n",
    "    mean2 = np.mean(flat2)\n",
    "    mean_comb = (mean1 + mean2) / 2.0\n",
    "\n",
    "    diff = flat1 - flat2\n",
    "    variance_diff = np.var(diff) / 2.0  # Because var(A - B) = 2 * var(single image)\n",
    "\n",
    "    gain = mean_comb / variance_diff\n",
    "\n",
    "    return float(gain)\n",
    "\n",
    "def calculate_readout_noise(files, gain):\n",
    "    \"\"\"\n",
    "    Calculate the readout noise in electrons (e-) using two bias frames.\n",
    "\n",
    "    Parameters:\n",
    "        files (list): List of two bias FITS file paths.\n",
    "        gain (float): Gain in e-/ADU.\n",
    "\n",
    "    Returns:\n",
    "        float: Readout noise in electrons.\n",
    "    \"\"\"\n",
    "    if len(files) != 2:\n",
    "        raise ValueError(\"You must provide exactly two bias frames.\")\n",
    "\n",
    "    # Read the bias frames\n",
    "    bias1 = fits.getdata(files[0]).astype(np.float32)\n",
    "    bias2 = fits.getdata(files[1]).astype(np.float32)\n",
    "\n",
    "    # Calculate variance of the difference\n",
    "    diff = bias1 - bias2\n",
    "    variance_diff = np.var(diff) / 2.0  # Same reasoning as above\n",
    "\n",
    "    readout_noise = np.sqrt(variance_diff) * gain\n",
    "\n",
    "    return float(readout_noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c20a788-02ac-48f5-a3fd-aac3636b751a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating gain and readout noise \n",
    "flat_files = [\"astr-480-env/work/arcsat_data/scripts/data/domeflat_g_001.fits\",\"astr-480-env/work/arcsat_data/scripts/data/domeflat_g_002.fits\"]\n",
    "bias_files = [\"astr-480-env/work/arcsat_data/scripts/data/Bias_BIN1_20250601_025309.fits\", \"astr-480-env/work/arcsat_data/scripts/data/Bias_BIN1_20250601_025324.fits\"]\n",
    "\n",
    "gain = calculate_gain(files = flat_files)\n",
    "read_noise = calculate_readout_noise(files = bias_files, gain = gain)\n",
    "\n",
    "print(f\"Gain: {gain:.3f} e-/ADU\")\n",
    "print(f\"Readout Noise: {read_noise:.2f} e-\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
